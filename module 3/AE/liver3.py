# -*- coding: utf-8 -*-
"""Liver3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qaVPs40f7JejzCQ7WMhKx6IJFJWXJZBb
"""

import tensorflow as tf
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score, f1_score, precision_score
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import pickle
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv("C:\\Users\\User\\Desktop\\fproject\\dataset\\liver_patient.csv")

df.head()

df.duplicated().sum()

df = df.drop_duplicates()

df.duplicated().sum()

df.isnull().sum()

df = df.dropna()

df.isnull().sum()

df = df.rename({'Dataset':'Result'},axis=1)

df.columns

from sklearn.preprocessing import LabelEncoder
var_mod = ['Gender']
le = LabelEncoder()
for i in var_mod:
  df[i] = le.fit_transform(df[i]).astype(int)

df_sex = pd.get_dummies(df['Gender'])
df_new = pd.concat([df, df_sex], axis=1)
Droop_gender = df_new.drop(labels=['Gender' ],axis=1 )
Droop_gender.columns = ['Age', 'Total_Bilirubin', 'Direct_Bilirubin','Alkaline_Phosphotase','Alamine_Aminotransferase','Aspartate_Aminotransferase','Total_Protiens','Albumin','Albumin_and_Globulin_Ratio','Male','Fmale','Result']

X = Droop_gender.drop('Result',axis=1)
y = Droop_gender['Result']

# split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1,stratify = y)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

input_shape = X_train.shape[1]
encoding_dim = 11

input_layer = tf.keras.Input(shape=(input_shape,))
encoded = tf.keras.layers.Dense(encoding_dim, activation='relu')(input_layer)
decoded = tf.keras.layers.Dense(input_shape, activation='sigmoid')(encoded)

autoencoder = tf.keras.Model(input_layer, decoded)
autoencoder.compile(optimizer='adam', loss='mse')

autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, validation_data=(X_test, X_test))

encoder = tf.keras.Model(input_layer, encoded)
encoded_input = tf.keras.Input(shape=(encoding_dim,))
classifier_layer = tf.keras.layers.Dense(1, activation='sigmoid')(encoded_input)
classifier = tf.keras.Model(encoded_input, classifier_layer)

classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
classifier.fit(encoder.predict(X_train), y_train, epochs=100, batch_size=32, validation_data=(encoder.predict(X_test), y_test))

y_pred = classifier.predict(encoder.predict(X_test))

y_pred = y_pred.round()

print(classification_report(y_test, y_pred))

print("Report")
accuracy = (accuracy_score(y_test,y_pred)*100)
print("Accuracy:", accuracy)

f1_score(y_test,y_pred)

recall_score(y_test,y_pred,average='weighted')

precision_score(y_test,y_pred)

print("Confusion matrix")
cm2=confusion_matrix(y_test,y_pred)
print(cm2)

sensitivity2 = cm2[1,1]/(cm2[1,1]+cm2[1,0])
print('Sensitivity : ', sensitivity2 )

specificity2 = cm2[0,0]/(cm2[0,0]+cm2[0,1])
print('Specificity : ',specificity2)

TN = cm2[0][0]
FN = cm2[1][0]
TP = cm2[1][1]
FP = cm2[0][1]
print("True Positive :",TP)
print("True Negative :",TN)
print("False Positive :",FP)
print("False Negative :",FN)
print("")
TPR = TP/(TP+FN)
TNR = TN/(TN+FP)
FPR = FP/(FP+TN)
FNR = FN/(TP+FN)
print("True Positive Rate :",TPR)
print("True Negative Rate :",TNR)
print("False Positive Rate :",FPR)
print("False Negative Rate :",FNR)
print("")
PPV = TP/(TP+FP)
NPV = TN/(TN+FN)
print("Positive Predictive Value :",PPV)
print("Negative predictive value :",NPV)


cm2=confusion_matrix(y_test, y_pred)
print('Confusion matrix:')
print(cm2)



sns.heatmap(cm2/np.sum(cm2), annot=True, cmap = 'Blues', annot_kws={"size": 16},fmt='.2%')
plt.show()

pickle.dump(classifier, open('Liver-AE.pkl', 'wb'))
